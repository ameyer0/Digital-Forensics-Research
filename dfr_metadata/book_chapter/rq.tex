\section{Research Questions}

\begin{paraphrase}
A DFR tool is a piece of software that can retrieve residual data of a file that was deleted 
from a storage device (e.g., computer hard disk, flash drive, and so on). We evaluate a set of 
popular DFR tools on the scale of CFTT guidelines. 
In particular, following are the research questions (RQs) that we target to answer. 

\begin{itemize}
\item[RQ1.] Do the popular metadata-based DFR tools meet the NIST CFTT expectation? 
If not, which tool meets which part of the expectation? 

\item[RQ2.] What factors make the metadata-based tools fail or succeed?

\item[RQ3.] Do the popular file carving tools meet the NIST CFTT expectation? 
If not, which tool meets which part of the expectation? 

\item[RQ4.] What factors make the file carving tools fail or succeed?

\end{itemize}

The identification of errors, such as for not recovering a deleted file or attempting to recover a file that was never there 
(Type I and Type II errors, respectively), is an important metric for a DFR tool. 
Type I and Type II errors account for majority of the standard. Many factors impact the performance of a DFR tool, 
including file system type, whether the file content is not located in contiguous clusters, whether 
some part of the deleted file content is overwritten by another file, and more.
We consider these variables in the design of experiment when we compare the tools.
Note that our current study is limited to exploring the \emph{core features} of NIST guidelines~\cite{meta:dfr:standards}, 
i.e., we leave the optional features~\cite{meta:dfr:standards} of NIST guidelines for future study. \TODO{work carving into this paragraph}
\end{paraphrase}


 
